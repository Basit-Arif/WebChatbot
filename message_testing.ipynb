{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "import regex as re\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_core.documents import Document as Langchain_Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from uuid import uuid4\n",
    "import langgraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from docx import Document as Dt\n",
    "\n",
    "def load_docx(file_path):\n",
    "    \"\"\"\n",
    "    Loads a .docx file and extracts its text content.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The path to the .docx file.\n",
    "        \n",
    "    Returns:\n",
    "        str: The full text content of the document.\n",
    "    \"\"\"\n",
    "    doc = Dt(file_path)\n",
    "    full_text = []\n",
    "    \n",
    "    # Extract paragraphs from docx\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    \n",
    "    # Join all paragraphs into a single string with newline as separator\n",
    "    return \"\\n\\n\".join(full_text)\n",
    "\n",
    "def split_document_by_paragraphs(document_content):\n",
    "    \"\"\"\n",
    "    Splits document content into paragraphs based on multiple newline characters.\n",
    "    \n",
    "    Args:\n",
    "        document_content (str): The full document text to be split.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of paragraphs from the document.\n",
    "    \"\"\"\n",
    "    # Regular expression to split paragraphs using 2 or more consecutive newline characters\n",
    "    paragraphs = re.split(r'\\n{2,}', document_content)\n",
    "    \n",
    "    # Remove leading/trailing whitespaces and empty paragraphs\n",
    "    paragraphs = [para.strip() for para in paragraphs if para.strip()]\n",
    "    \n",
    "    return paragraphs\n",
    "\n",
    "def convert_to_page_content(paragraphs):\n",
    "    \"\"\"\n",
    "    Converts paragraphs to the desired page_content and metadata format.\n",
    "    \n",
    "    Args:\n",
    "        paragraphs (list): List of paragraphs from the document.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries containing 'page_content' and 'metadata' for each paragraph.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for idx, paragraph in enumerate(paragraphs):\n",
    "        doc = Langchain_Document(\n",
    "            page_content=paragraph,\n",
    "            metadata={\n",
    "                \"source\": f\"Paragraph {idx + 1}\"\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Load the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx_file_path = \"portfolio_text.docx\"  # Replace with the path to your .docx file\n",
    "document_content = load_docx(docx_file_path)\n",
    "\n",
    "# Split the document into paragraphs\n",
    "paragraphs = split_document_by_paragraphs(document_content)\n",
    "\n",
    "# Convert paragraphs to page_content and metadata\n",
    "formatted_content = convert_to_page_content(paragraphs)\n",
    "\n",
    "# Example output: Display each paragraph in the desired format\n",
    "list_of_document=[document for document in formatted_content]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids = [str(uuid4()) for _ in range(len(list_of_document))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70ccd04932f4de49f5539d1dfce5a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e904c64240f6474e99e8cc132574555c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670ca8c3df404646a8076d9aba8fc121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07ca0e205b74d24af46ce7a560d3966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aafb5534fd6f473e81515d1534d5f300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430f6061dbe1472a86368158fdc7b57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a180630e194f46816e6231402a3d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed36a04c58cb4a44a074f341b94d1141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20b43de8904453998bf05094613157e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08777c33ba5447aa12811e98353fc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de19dece0df74fd1961081f1451177f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_astradb import AstraDBVectorStore\n",
    "\n",
    "vector_store = AstraDBVectorStore(\n",
    "    collection_name=\"portfolio\",\n",
    "    embedding=hf,\n",
    "    api_endpoint=\"https://ab0b8a51-9354-4c38-9d62-0fbbcb8b90cb-us-east-2.apps.astra.datastax.com\",\n",
    "    token=\"AstraCS:kQJxeuvgFZJZBYLNZYUaZrOU:2bb633a7989422ac09098e6620a818cefcbd2cf44c3af544f457581a3cf51910\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ba7c7a25-5dbd-4369-b0a3-009a5d3391c1',\n",
       " '13b2dcb1-4eb8-4cdc-93d7-151507677375',\n",
       " '598844af-8e85-4ad5-8980-099107d4bf58',\n",
       " 'f162642c-850c-42ad-aaf6-26149a00781d',\n",
       " 'cb772668-ab05-4a03-9de6-9929dd5a1329',\n",
       " 'eb522106-9fd7-4219-be4d-5c954ea842f1',\n",
       " '09ca8def-dddc-4965-b179-56017f2da7e0']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=list_of_document, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "retreiver=vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='13b2dcb1-4eb8-4cdc-93d7-151507677375', metadata={'source': 'Paragraph 2'}, page_content='\"I approach projects by first breaking down the problem into its core components. For example, in one chatbot I built, the goal was to automate customer support for an e-commerce platform. I designed the chatbot to understand customer queries using NLP models, and then leveraged LangChain to connect the bot with real-time data sources. I also integrated the bot into existing systems, ensuring it could provide relevant information from databases and even handle payments. I focus on creating solutions that are easy to implement and maintain, always with scalability in mind.\"'),\n",
       " Document(id='09ca8def-dddc-4965-b179-56017f2da7e0', metadata={'source': 'Paragraph 7'}, page_content='Paragraph 7:\\n\"Ultimately, my work is about creating impact. Every AI project I\\'ve worked on has been aimed at solving real-world business problems—whether it’s reducing operational costs, automating repetitive tasks, or delivering insights from large datasets. I’ve deployed AI models that not only predict outcomes but also provide actionable solutions. Let’s talk about how we can use AI to optimize your business, automate your processes, or solve the unique challenges you’re facing. I’m here to help you take your project from idea to execution.\"'),\n",
       " Document(id='ba7c7a25-5dbd-4369-b0a3-009a5d3391c1', metadata={'source': 'Paragraph 1'}, page_content='\"Hello! I’m Abdul Basit, a data scientist and AI developer. I’ve built end-to-end AI applications from scratch, including chatbots, intelligent document readers, and inventory management systems. Each project involved problem-solving at multiple levels—starting with understanding the needs of the business, identifying inefficiencies, and applying data science and AI to address these challenges. I’ve used tools like Python, Flask, and SQLAlchemy for backend development, and incorporated advanced AI technologies like OpenAI and LangChain to ensure that these solutions were intelligent, adaptable, and scalable.\"'),\n",
       " Document(id='eb522106-9fd7-4219-be4d-5c954ea842f1', metadata={'source': 'Paragraph 6'}, page_content='\"When someone presents a problem, I approach it with a solution-driven mindset. I’ve built chatbots that help businesses communicate better with their customers, and I’ve developed models that make sense of large datasets. For instance, if you need a system to automate customer inquiries, this chatbot can give you suggestions on how to build that—whether it\\'s integrating with a CRM, setting up intent recognition with NLP, or handling real-time customer data. My approach is always practical, focused on delivering a working solution that fits within the specific context of the problem.\"')]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retreiver.invoke(\"how he develop something\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.similarity_search_with_score(\"show your portfolio\")\n",
    "from  langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPEN_API_KEY\")\n",
    "model=ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    chain_type='stuff',\n",
    "    llm=model, retriever=vector_store.as_retriever(),memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to your previous question. If you can provide me with more information or context, I'll do my best to help you.\""
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke(\"what was my previos question\")[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what was my previous question',\n",
       " 'chat_history': [HumanMessage(content='did basit build customize chatbot', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, Abdul Basit has experience building customized chatbots. He has developed chatbots to automate customer support for e-commerce platforms, focusing on understanding customer queries using NLP models, integrating with real-time data sources, databases, and handling payments. His approach involves creating solutions that are tailored to the specific needs of businesses and are designed to be intelligent, adaptable, and scalable.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what was my previos question', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to your previous question. How can I assist you today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what was my previous question', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I'm sorry, but based on the provided context, there is no specific previous question mentioned. If you have a question you'd like assistance with, please feel free to ask.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what was my previous question', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't have access to your previous question.\", additional_kwargs={}, response_metadata={})],\n",
       " 'result': \"I don't have access to your previous question.\"}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='did basit build customize chatbot', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, Abdul Basit has experience building customized chatbots. He has developed chatbots to automate customer support for e-commerce platforms, focusing on understanding customer queries using NLP models, integrating with real-time data sources, databases, and handling payments. His approach involves creating solutions that are tailored to the specific needs of businesses and are designed to be intelligent, adaptable, and scalable.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what was my previos question', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to your previous question. How can I assist you today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what was my previous question', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I'm sorry, but based on the provided context, there is no specific previous question mentioned. If you have a question you'd like assistance with, please feel free to ask.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what was my previous question', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't have access to your previous question.\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78a73e9cea53431a004a8cb57099f417374d636685740d6545615ecc2fea032b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
